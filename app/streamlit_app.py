"""
ğŸ¥ ë³‘ì› ê³ ê° ì§ˆì˜ì‘ë‹µ RAG ì±—ë´‡ Streamlit ì•± (ì™„ì „ ë²„ì „)
"""
import streamlit as st
import os
import sys
import yaml
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ¥ ë³‘ì› ê³ ê° ì§ˆì˜ì‘ë‹µ RAG ì±—ë´‡",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì œëª© ë° ì„¤ëª…
st.title("ğŸ¥ ë³‘ì› ê³ ê° ì§ˆì˜ì‘ë‹µ RAG ì±—ë´‡")
st.markdown("**AI ê¸°ë°˜ ë³‘ì› ê³ ê° ìƒë‹´ ì‹œìŠ¤í…œ - ì§ˆë¬¸í•˜ì‹œë©´ ì „ë¬¸ì ì¸ ë‹µë³€ì„ ë“œë¦½ë‹ˆë‹¤**")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •")
    
    # API í‚¤ ìƒíƒœ í™•ì¸
    st.subheader("ğŸ”‘ API í‚¤ ìƒíƒœ")
    openai_key = os.getenv('OPENAI_API_KEY')
    if openai_key:
        st.success("âœ… OpenAI API í‚¤ ì„¤ì •ë¨")
    else:
        st.error("âŒ OpenAI API í‚¤ ì—†ìŒ")
        st.info("Streamlit Cloudì—ì„œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    # ì‹œìŠ¤í…œ ìƒíƒœ
    st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
    if 'rag_system' in st.session_state:
        st.success("âœ… RAG ì‹œìŠ¤í…œ ë¡œë“œë¨")
    else:
        st.warning("âš ï¸ RAG ì‹œìŠ¤í…œ ë¡œë”© ì¤‘...")
    
    # í†µê³„ ì •ë³´
    st.subheader("ğŸ“ˆ ì‚¬ìš© í†µê³„")
    if 'chat_history' in st.session_state:
        st.metric("ì´ ì§ˆë¬¸ ìˆ˜", len(st.session_state.chat_history))
    else:
        st.metric("ì´ ì§ˆë¬¸ ìˆ˜", 0)

# ì™„ì „í•œ RAG ì‹œìŠ¤í…œ (OpenAI ê¸°ë°˜)
class FullRAGSystem:
    """ì™„ì „í•œ RAG ì‹œìŠ¤í…œ (OpenAI GPT-4 í™œìš©)"""
    
    def __init__(self):
        self.openai_key = os.getenv('OPENAI_API_KEY')
        if not self.openai_key:
            st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def query(self, question: str):
        """OpenAI GPT-4ë¥¼ ì‚¬ìš©í•œ ì§ˆì˜ì‘ë‹µ"""
        try:
            import openai
            
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            client = openai.OpenAI(api_key=self.openai_key)
            
            # ë³‘ì› ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
            system_prompt = """ë‹¹ì‹ ì€ ë³‘ì› ê³ ê° ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
            ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì „ë¬¸ì ì´ê³  ì¹œì ˆí•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
            ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."""
            
            # GPT-4 API í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": question}
                ],
                max_tokens=500,
                temperature=0.1
            )
            
            answer = response.choices[0].message.content
            confidence = 0.9  # GPT-4ëŠ” ë†’ì€ ì‹ ë¢°ë„
            
            return {
                'answer': answer,
                'source_documents': [],
                'confidence': confidence,
                'question': question
            }
            
        except Exception as e:
            # OpenAI API ì‹¤íŒ¨ì‹œ Mock ë‹µë³€
            mock_answers = {
                "ì˜ˆì•½": "ì˜ˆì•½ì€ ì „í™”(02-1234-5678) ë˜ëŠ” ì˜¨ë¼ì¸(www.hospital.com)ìœ¼ë¡œ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                "ì·¨ì†Œ": "ì˜ˆì•½ ì·¨ì†ŒëŠ” ì§„ë£Œ 24ì‹œê°„ ì „ê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì „í™” ë˜ëŠ” ì˜¨ë¼ì¸ìœ¼ë¡œ ì·¨ì†Œí•´ì£¼ì„¸ìš”.",
                "ì§„ë£Œì‹œê°„": "í‰ì¼ ì˜¤ì „ 9ì‹œë¶€í„° ì˜¤í›„ 6ì‹œê¹Œì§€, í† ìš”ì¼ ì˜¤ì „ 9ì‹œë¶€í„° ì˜¤í›„ 1ì‹œê¹Œì§€ ì§„ë£Œí•©ë‹ˆë‹¤.",
                "ì‘ê¸‰ì‹¤": "ì‘ê¸‰ì‹¤ì€ 24ì‹œê°„ ìš´ì˜ë©ë‹ˆë‹¤. ì‘ê¸‰ìƒí™© ì‹œ 119ì— ì‹ ê³ í•˜ì„¸ìš”.",
                "ë°€í¬ì‹œìŠ¬": "ë°€í¬ì‹œìŠ¬(Milk Thistle)ì€ ê°„ ê±´ê°•ì— ë„ì›€ì„ ì£¼ëŠ” ì²œì—° ë³´ì¡°ì œì…ë‹ˆë‹¤. ê°„ ê¸°ëŠ¥ ê°œì„ ê³¼ í•´ë… ì‘ìš©ì— ë„ì›€ì´ ë©ë‹ˆë‹¤. ì²˜ë°©ì „ ì—†ì´ êµ¬ì… ê°€ëŠ¥í•˜ì§€ë§Œ, ë³µìš© ì „ ì˜ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
            }
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            matched_key = None
            for key in mock_answers.keys():
                if key in question:
                    matched_key = key
                    break
            
            if matched_key:
                answer = mock_answers[matched_key]
                confidence = 0.8
            else:
                answer = "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì „í™”(02-1234-5678)ë¡œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
                confidence = 0.3
            
            return {
                'answer': answer,
                'source_documents': [],
                'confidence': confidence,
                'question': question
            }

# Streamlitìš© RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
@st.cache_resource
def get_rag_system():
    """Streamlitì—ì„œ ì‚¬ìš©í•  RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤"""
    return FullRAGSystem()

# ë©”ì¸ ì»¨í…ì¸ 
col1, col2 = st.columns([2, 1])

with col1:
    st.header("ğŸ’¬ ì§ˆì˜ì‘ë‹µ")
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # ì§ˆë¬¸ ì…ë ¥
    user_question = st.text_area(
        "ë³‘ì› ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”:",
        placeholder="ì˜ˆ: ì˜ˆì•½ ì·¨ì†ŒëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
        height=100
    )
    
    # ë¶„ì„ ì˜µì…˜
    col_opt1, col_opt2 = st.columns(2)
    with col_opt1:
        show_sources = st.checkbox("ê´€ë ¨ ë¬¸ì„œ í‘œì‹œ", value=True)
    with col_opt2:
        show_confidence = st.checkbox("ì‹ ë¢°ë„ í‘œì‹œ", value=True)
    
    # ì§ˆë¬¸ ì œì¶œ ë²„íŠ¼
    if st.button("ğŸ” ë‹µë³€ ìš”ì²­", type="primary", use_container_width=True):
        if user_question.strip():
            with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
                if 'rag_system' not in st.session_state:
                    st.session_state.rag_system = get_rag_system()
                
                # ì§ˆì˜ ì²˜ë¦¬
                result = st.session_state.rag_system.query(user_question)
                
                # ê²°ê³¼ë¥¼ ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                st.session_state.chat_history.append({
                    'timestamp': datetime.now(),
                    'question': user_question,
                    'answer': result['answer'],
                    'confidence': result['confidence'],
                    'sources': result['source_documents']
                })
                
                st.success("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ!")
        else:
            st.warning("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

with col2:
    st.header("ğŸ“Š ë‹µë³€ ê²°ê³¼")
    
    if st.session_state.chat_history:
        latest_result = st.session_state.chat_history[-1]
        
        # ë‹µë³€ í‘œì‹œ
        st.subheader("ğŸ’¡ ë‹µë³€")
        st.write(latest_result['answer'])
        
        # ì‹ ë¢°ë„ í‘œì‹œ
        if show_confidence:
            confidence_score = latest_result['confidence']
            st.subheader("ğŸ¯ ì‹ ë¢°ë„")
            st.progress(confidence_score)
            st.caption(f"ì‹ ë¢°ë„: {confidence_score:.1%}")
        
        # ê´€ë ¨ ë¬¸ì„œ í‘œì‹œ
        if show_sources and latest_result['sources']:
            st.subheader("ğŸ“š ê´€ë ¨ ë¬¸ì„œ")
            for i, doc in enumerate(latest_result['sources'][:3]):
                with st.expander(f"ë¬¸ì„œ {i+1}"):
                    st.write(f"**ì§ˆë¬¸:** {doc.metadata.get('question', 'N/A')}")
                    st.write(f"**ë‹µë³€:** {doc.metadata.get('answer', 'N/A')}")
                    st.write(f"**ê´€ë ¨ë„:** {doc.metadata.get('score', 'N/A')}")

# ì±„íŒ… íˆìŠ¤í† ë¦¬
if st.session_state.chat_history:
    st.header("ğŸ“ ëŒ€í™” íˆìŠ¤í† ë¦¬")
    
    # íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for i, chat in enumerate(reversed(st.session_state.chat_history)):
        with st.expander(f"ì§ˆë¬¸ {len(st.session_state.chat_history)-i}: {chat['question'][:50]}..."):
            col_q, col_a = st.columns([1, 2])
            
            with col_q:
                st.write("**ì§ˆë¬¸:**")
                st.write(chat['question'])
                st.caption(f"ì‹œê°„: {chat['timestamp'].strftime('%H:%M:%S')}")
            
            with col_a:
                st.write("**ë‹µë³€:**")
                st.write(chat['answer'])
                if show_confidence:
                    st.caption(f"ì‹ ë¢°ë„: {chat['confidence']:.1%}")

# í†µê³„ ë° ë¶„ì„
if len(st.session_state.chat_history) > 0:
    st.header("ğŸ“ˆ ì‚¬ìš© í†µê³„")
    
    # ê¸°ë³¸ í†µê³„
    col_stat1, col_stat2, col_stat3 = st.columns(3)
    
    with col_stat1:
        st.metric("ì´ ì§ˆë¬¸ ìˆ˜", len(st.session_state.chat_history))
    
    with col_stat2:
        avg_confidence = sum(chat['confidence'] for chat in st.session_state.chat_history) / len(st.session_state.chat_history)
        st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.1%}")
    
    with col_stat3:
        total_sources = sum(len(chat['sources']) for chat in st.session_state.chat_history)
        st.metric("ì´ ì°¸ì¡° ë¬¸ì„œ", total_sources)
    
    # ì‹ ë¢°ë„ ë¶„í¬ ì°¨íŠ¸
    if len(st.session_state.chat_history) > 1:
        confidence_data = [chat['confidence'] for chat in st.session_state.chat_history]
        
        fig = px.histogram(
            x=confidence_data,
            nbins=10,
            title="ì‹ ë¢°ë„ ë¶„í¬",
            labels={'x': 'ì‹ ë¢°ë„', 'y': 'ë¹ˆë„'}
        )
        st.plotly_chart(fig, use_container_width=True)

# í‘¸í„°
st.markdown("---")
st.markdown("**ğŸ¥ ë³‘ì› ê³ ê° ì§ˆì˜ì‘ë‹µ RAG ì‹œìŠ¤í…œ** - AI ê¸°ë°˜ ê³ ê° ìƒë‹´ ì†”ë£¨ì…˜")
st.caption("Â© 2025 ì„œê°•ì‹ í”„ë¡œì íŠ¸. All rights reserved.")

# ë””ë²„ê·¸ ì •ë³´ (ê°œë°œ ëª¨ë“œì—ì„œë§Œ)
if st.sidebar.checkbox("ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ"):
    st.header("ğŸ”§ ë””ë²„ê·¸ ì •ë³´")
    
    st.subheader("í™˜ê²½ ë³€ìˆ˜")
    st.write(f"OpenAI API Key: {'ì„¤ì •ë¨' if openai_key else 'ì„¤ì • ì•ˆë¨'}")
    
    st.subheader("ì„¸ì…˜ ìƒíƒœ")
    st.write(f"RAG ì‹œìŠ¤í…œ: {'ë¡œë“œë¨' if 'rag_system' in st.session_state else 'ë¡œë“œ ì•ˆë¨'}")
    st.write(f"ì±„íŒ… íˆìŠ¤í† ë¦¬: {len(st.session_state.chat_history)}ê°œ")
    
    if st.button("ğŸ—‘ï¸ ì„¸ì…˜ ì´ˆê¸°í™”"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()