"""
ë³‘ì› ê³ ê° ì§ˆì˜ì‘ë‹µ RAG ì‹œìŠ¤í…œ
"""
import os
import pickle
from typing import List, Dict, Any
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_openai import OpenAI
from langchain.schema import Document
import yaml
import streamlit as st

class HospitalRAGSystem:
    """ë³‘ì› RAG ì‹œìŠ¤í…œ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.embeddings = None
        self.vectorstore = None
        self.retriever = None
        self.qa_chain = None
        
    def setup_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ì„¤ì •"""
        try:
            # OpenAI ì„ë² ë”© ì‚¬ìš©
            self.embeddings = OpenAIEmbeddings(
                openai_api_key=os.getenv('OPENAI_API_KEY')
            )
            print("âœ… OpenAI ì„ë² ë”© ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")
            # ëŒ€ì²´ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
            from sentence_transformers import SentenceTransformer
            self.embeddings = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            print("âœ… SentenceTransformer ì„ë² ë”© ëª¨ë¸ ì„¤ì • ì™„ë£Œ")
    
    def load_qa_data(self, data_path: str) -> List[Dict]:
        """Q&A ë°ì´í„° ë¡œë“œ"""
        try:
            with open(data_path, 'rb') as f:
                qa_pairs = pickle.load(f)
            print(f"âœ… Q&A ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(qa_pairs)}ê°œ ìƒ˜í”Œ")
            return qa_pairs
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def create_documents(self, qa_pairs: List[Dict]) -> List[Document]:
        """Document ê°ì²´ ìƒì„±"""
        documents = []
        
        for qa in qa_pairs:
            # ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê²°í•©í•œ í…ìŠ¤íŠ¸ ìƒì„±
            content = f"ì§ˆë¬¸: {qa['question']}\në‹µë³€: {qa['answer']}"
            
            doc = Document(
                page_content=content,
                metadata={
                    'id': qa['id'],
                    'question': qa['question'],
                    'answer': qa['answer'],
                    'category': qa['category'],
                    **qa['metadata']
                }
            )
            documents.append(doc)
        
        return documents
    
    def setup_vectorstore(self, documents: List[Document]):
        """ë²¡í„° ì €ì¥ì†Œ ì„¤ì •"""
        try:
            # í…ìŠ¤íŠ¸ ë¶„í• 
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.config['model']['chunk_size'],
                chunk_overlap=self.config['model']['chunk_overlap']
            )
            
            splits = text_splitter.split_documents(documents)
            print(f"âœ… ë¬¸ì„œ ë¶„í•  ì™„ë£Œ: {len(splits)}ê°œ ì²­í¬")
            
            # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
            self.vectorstore = Chroma.from_documents(
                documents=splits,
                embedding=self.embeddings,
                persist_directory=self.config['data']['vectorstore_path']
            )
            
            # ê²€ìƒ‰ê¸° ì„¤ì •
            self.retriever = self.vectorstore.as_retriever(
                search_kwargs={"k": self.config['rag']['top_k']}
            )
            
            print("âœ… ë²¡í„° ì €ì¥ì†Œ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë²¡í„° ì €ì¥ì†Œ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def setup_qa_chain(self):
        """Q&A ì²´ì¸ ì„¤ì •"""
        try:
            llm = OpenAI(
                openai_api_key=os.getenv('OPENAI_API_KEY'),
                model_name=self.config['model']['llm_model'],
                temperature=0.1,
                max_tokens=self.config['rag']['max_tokens']
            )
            
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=self.retriever,
                return_source_documents=True
            )
            
            print("âœ… Q&A ì²´ì¸ ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ Q&A ì²´ì¸ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def query(self, question: str) -> Dict[str, Any]:
        """ì§ˆì˜ì‘ë‹µ ì²˜ë¦¬"""
        try:
            if self.qa_chain is None:
                return {
                    'answer': 'RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                    'source_documents': [],
                    'confidence': 0.0
                }
            
            # ì§ˆì˜ ì²˜ë¦¬
            result = self.qa_chain({"query": question})
            
            # ê²°ê³¼ ì •ë¦¬
            answer = result['result']
            source_docs = result['source_documents']
            
            # ì‹ ë¢°ë„ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
            confidence = min(1.0, len(source_docs) / self.config['rag']['top_k'])
            
            return {
                'answer': answer,
                'source_documents': source_docs,
                'confidence': confidence,
                'question': question
            }
            
        except Exception as e:
            return {
                'answer': f'ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}',
                'source_documents': [],
                'confidence': 0.0,
                'question': question
            }
    
    def initialize_system(self):
        """ì „ì²´ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ğŸš€ ë³‘ì› RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        
        # 1. ì„ë² ë”© ì„¤ì •
        self.setup_embeddings()
        
        # 2. ë°ì´í„° ë¡œë“œ
        train_qa_pairs = self.load_qa_data("data/processed/train_qa_pairs.pkl")
        
        if not train_qa_pairs:
            print("âŒ í›ˆë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # 3. ë¬¸ì„œ ìƒì„±
        documents = self.create_documents(train_qa_pairs)
        
        # 4. ë²¡í„° ì €ì¥ì†Œ ì„¤ì •
        self.setup_vectorstore(documents)
        
        # 5. Q&A ì²´ì¸ ì„¤ì •
        self.setup_qa_chain()
        
        print("âœ… ë³‘ì› RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        return True

# Streamlitìš© RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
@st.cache_resource
def get_rag_system():
    """Streamlitì—ì„œ ì‚¬ìš©í•  RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤"""
    rag_system = HospitalRAGSystem()
    rag_system.initialize_system()
    return rag_system
